{"cells":[{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import numpy\n","import numpy as np\n","import itertools as it \n","import gym\n","import torch\n","import torch.nn.functional as F \n","import torch.nn as nn\n","from torch.autograd import Variable\n","from skimage import color\n","import torch.optim as optim\n","from collections import deque\n","import matplotlib.pyplot as plt\n","\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#copy\n","\n","class ScaleFloatFram(gym.ObservationWrapper):\n","    def observation(self, obs):\n","        return np.array(obs).astype(np.float64)\n","\n","def make_env(env_name):\n","    env = gym.make(env_name)\n","    return env\n","    #return ScaleFloatFram(env)\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"/Users/roxanefischer/.local/share/virtualenvs/code-i1XZ64Tp/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\nTrack generation: 1240..1554 -> 314-tiles track\n"}],"source":["env_name = \"CarRacing-v0\"\n","env = make_env(env_name)\n","ob =env.reset()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["#To understand\n","def one_step(i :int):\n","    action = env.action_space.sample()\n","    #action = [0,1,1]\n","    observation, reward, done, info = env.step(action)\n","    if (i%10==0):\n","        print(f\" action : {action}\")\n","        print(f\"reward : {reward}\")\n","        print(f\"done : {done}\")\n","        plt.show()\n","        plt.imshow(observation)\n","        print(\"------------------\")\n","\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["np.random.RandomState(42)\n","n_episode = 2\n","max_horizon = 100\n","batch_size = 3\n","gamma = 0.9 \n","num_frame_stack = 4\n","epsilon = 0.1\n","\n","#direction frein acceleration\n","all_actions = np.array( [k for k in it.product([-1, 0, 1], [1, 0], [0.2, 0])])\n","nb_actions = len(all_actions)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class Unflatten(nn.Module):\n","    \"\"\"\n","    An Unflatten module receives an input of shape (N, C*H*W) and reshapes it\n","    to produce an output of shape (N, C, H, W).\n","    \"\"\"\n","    def __init__(self, N=-1, C=3,H=96, W=96):\n","        super(Unflatten, self).__init__()\n","        self.N = N\n","        self.C = C\n","        self.H = H\n","        self.W = W\n","    def forward(self, x):\n","        return x.view(self.N, self.C,self.H, self.W)\n","\n","class Flatten(nn.Module):\n","    def forward(self, x):\n","        N, C, H, W = x.size() # read in N, C, H, W\n","        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["class Q_model(nn.Module):\n","    \"\"\"\n","    Build and return a PyTorch model implementing the architecture above.\n","    \"\"\"\n","\n","    def __init__(self, batch_size=1, nb_frames=4, output_dim=nb_actions, trainable=True):\n","        super(Q_model,self).__init__()\n","        self.model = nn.Sequential(\n","                # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","                Unflatten(batch_size, nb_frames, 96, 96),\n","                #Unflatten(1, 3, 96, 96),\n","                nn.Conv2d(in_channels=4, out_channels=16, kernel_size=7, stride=3), #46\n","                nn.LeakyReLU(inplace=True, negative_slope=0.01),\n","                nn.MaxPool2d(kernel_size=2, stride=2),\n","                nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2), #42\n","                nn.LeakyReLU(inplace=True, negative_slope=0.01),\n","                nn.MaxPool2d(kernel_size=2, stride=2), #21\n","                Flatten(),\n","                nn.Linear(288, 256),\n","                nn.LeakyReLU(inplace=True, negative_slope=0.01),\n","                nn.Linear(256, output_dim),)\n","\n","            #nn.Linear(input_dim,48),\n","            #nn.LeakyReLU(0.01),\n","            #nn.Linear(48,48),\n","            #nn.LeakyReLU(0.01),\n","            #nn.Linear(48,output_dim)\n","            \n","\n","            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    \n","    def forward(self,x):\n","         return self.model(x)"]},{"cell_type":"markdown","execution_count":47,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"can't assign to function call (<ipython-input-47-f302ac683773>, line 1)","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-f302ac683773>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    torch.Size([2, 28224]) = 64 * 21 *21\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"]}],"source":"torch.Size([2, 28224]) = 64 * 21 *21\n"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"\ndef initialize_deque(obs,num_frame_stack=num_frame_stack):\n    d = deque(maxlen=num_frame_stack)\n    for i in range(num_frame_stack):\n        d.appendleft(obs)\n    return d\n\ndef stack_to_vector(deque : deque):\n    array = np.array(deque)\n    return torch.from_numpy(array).float()\n    \ndef to_grey(obs):\n    return color.rgb2gray(obs) \n\ndef find_index(all_actions, action):\n    for i in range(len(all_actions)):\n        if (np.array_equal(all_actions[i],action)):\n            return i\n"},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":"\n#optimizer = optim.Adam(Q.parameters(), lr=0.001, betas=(0.5, 0.999))\nmemory = list()\n\ndef main():\n    for i_episode in range(n_episode):\n        print(f\"Episode nb : {i_episode}\")\n        observation = env.reset()\n        d=initialize_deque(to_grey(observation))\n\n        for i_step in range(max_horizon):\n            stack = stack_to_vector(d)\n            Q_current = Q((stack))\n            #select the best action\n            greedy_ind = np.argmax(Q_current.detach().numpy())\n            action = all_actions[greedy_ind]\n           \n    \n            #execute action\n            obs_next, reward, done, info = env.step(action)\n            d.appendleft(to_grey(obs_next))\n            stack_next = stack_to_vector(d)\n            #store trnasition\n            memory.append({\"st\":stack,\"at\":action,\"rt\":reward,\"st+1\":stack_next})\n            #sample minibatch\n            selection = numpy.random.choice(memory, size=batch_size, replace=True)\n\n            rewards=torch.empty(batch_size)\n            #computed_rewards=torch.empty(batch_size)\n            loss = 0.0\n            optimizer.zero_grad()\n            for m in range(batch_size):\n                stack=selection[m][\"st\"]\n                stack_next = selection[m][\"st+1\"]\n                rewards[m]= selection[m][\"rt\"]\n                if (done == False):\n                    greedy_max = np.max(Q(stack_next).detach().numpy())\n                    rewards[m] =+ gamma*greedy_max\n                loss+= F.mse_loss(Q(stack), rewards[m])\n            #loss= F.mse_loss(computed_rewards, rewards)\n\n            loss.backward()\n            #print(loss)\n            #print()\n\n    \n\n"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["\n","np.random.RandomState(42)\n","n_episode = 20\n","max_horizon = 100\n","batch_size = 10\n","gamma = 0.9 \n","num_frame_stack = 4\n","epsilon = 0.1\n","learning_rate = 0.01\n","\n","#direction frein acceleration\n","all_actions = np.array( [k for k in it.product([-1, 0, 1], [1, 0], [0.2, 0])])\n","nb_actions = len(all_actions)\n",""]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["tab_loss = list()\n","memory = list()\n","class Agent():\n","    def __init__(self):\n","        self.target_network = Q_model(batch_size=1, nb_frames=4, output_dim=nb_actions, trainable=True)\n","        self.estimate_network = Q_model(batch_size=1, nb_frames=4, output_dim=nb_actions, trainable=True)\n","        self.optimizer = optim.Adam(self.estimate_network.parameters(),lr=learning_rate)\n","        self.target_parameters = self.target_network.parameters()\n","        self.estimate_parameters = self.estimate_network.parameters()\n","        self.frame = None\n","\n","\n","        self.target_network.eval()\n","        self.estimate_network.train()\n","\n","    def init_frame(self, obs,num_frame_stack=num_frame_stack):\n","        d = deque(maxlen=num_frame_stack)\n","        for i in range(num_frame_stack):\n","            d.appendleft(to_grey(obs))\n","        return d\n","    \n","    def reinitialisation_episode(self):\n","        observation = env.reset()\n","        self.frame = self.init_frame(observation)\n","\n","\n","    def update_target_network(self, tau = 0.1):\n","        for target_param, local_param in zip(self.target_network.parameters(),self.estimate_network.parameters()):\n","            target_param.data.copy_(tau*local_param.data + (1-tau)*target_param.data)\n","        #assert(len(self.target_parameters)==len(self.estimate_parameters))\n","       #for param in range(self.target_parameters):\n","                        \n","                        \n","\n","    def take_action(self, eps):\n","        proba = np.random.uniform(0, 1)\n","        #print(proba)\n","        if (proba > eps) :\n","            #print(\"proba >eps \")\n","            with torch.no_grad():\n","                stack = stack_to_vector(self.frame)\n","                Q_current = self.estimate_network((stack))\n","                print(Q_current)\n","                #select the best action\n","                greedy_ind = np.argmax(Q_current.detach().numpy())\n","                action = all_actions[greedy_ind]\n","        else :\n","           # print(\"proba <eps \")\n","            action_ind = np.random.randint(0, nb_actions)\n","            action =  all_actions[action_ind]\n","        return action\n","\n","    def learn_from_action(self, action):\n","        obs_next, reward, done, info = env.step(action)\n","        stack = stack_to_vector(self.frame)\n","        self.frame.appendleft(to_grey(obs_next))\n","        stack_next = stack_to_vector(self.frame)\n","        #store trnasition\n","        memory.append({\"st\":stack,\"at\":action, \"rt\":reward,\"st+1\":stack_next})\n","        #sample minibatch\n","        selection = numpy.random.choice(memory, size=batch_size, replace=True)\n","\n","        loss_function = nn.MSELoss()\n","\n","        # self.target_network.eval()\n","        # self.estimate_network.train()\n","\n","        targets=torch.empty(batch_size)\n","        predicted=torch.empty(batch_size)\n","\n","        for m in range(batch_size):\n","            action = selection[m][\"at\"]\n","            index_action = find_index(all_actions, action)\n","            with torch.no_grad():\n","                targets[m]= selection[m][\"rt\"]\n","                if (done == False):\n","                    stack_next = selection[m][\"st+1\"]\n","                    greedy_max = np.max(self.target_network(stack_next).detach().numpy())\n","                    targets[m] =+ gamma*greedy_max\n","                #loss+= F.mse_loss(Q(stack), rewards[m])\n","            stack = selection[m][\"st\"]\n","            #rint(f\"index {index_action}\")\n","            #print(len(predicted))\n","            #print(f\"output size {len(self.estimate_network(stack)[0])}\")\n","            #print(f\"output size {len(self.target_network(stack))}\")\n","            #print(self.estimate_network(stack))\n","            predicted[m] = self.estimate_network(stack)[0][index_action]\n","        \n","        loss = loss_function(predicted, targets)\n","        tab_loss.append(loss)\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        self.optimizer.step()\n","        self.update_target_network()\n","\n","\n","\n","\n","\n",""]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def run():\n","    agent = Agent()\n","    for i_episode in range(n_episode):\n","        print(f\"ie episode : {i_episode}\")\n","        agent.reinitialisation_episode()\n","        for i_step in range(max_horizon):\n","            action = agent.take_action(epsilon)\n","            agent.learn_from_action(action)\n","\n",""]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"ie episode : 0\nTrack generation: 1101..1380 -> 279-tiles track\ntensor([[-0.0377,  0.0128, -0.0232,  0.0175,  0.0704,  0.0254,  0.0402,  0.0369,\n         -0.0586,  0.0050, -0.0825,  0.0194]])\ntensor([[ 0.1767, -0.4535,  0.0433, -0.2378,  3.8729, -0.1163, -0.0506,  0.1853,\n         -0.3984,  0.1934,  0.1437, -0.2927]])\ntensor([[-0.1769, -0.0058,  0.0957,  0.1597, -0.2075, -0.1767,  0.0952,  0.4067,\n         -0.0086, -0.0598, -0.2838,  0.1456]])\ntensor([[-0.1637, -0.0383,  0.2180, -0.0188,  0.2669, -0.2838,  0.3658, -0.2814,\n          0.0208,  0.0022,  0.0075,  0.0290]])\ntensor([[-0.1451,  0.0077,  0.0491,  0.0505,  0.2491, -0.2588, -0.1493, -0.1512,\n         -0.0273, -0.0827, -0.0179,  0.0321]])\ntensor([[-0.0378,  0.0422, -0.0304,  0.0985,  0.0008, -0.1414, -0.0626, -0.0356,\n          0.0216, -0.0979, -0.0468,  0.0599]])\ntensor([[ 0.0200,  0.1058,  0.1087,  0.0196, -0.1098, -0.0589,  0.0579,  0.0033,\n          0.0275, -0.0615,  0.0212,  0.0463]])\ntensor([[ 0.0293,  0.0489,  0.0681, -0.0527, -0.0628, -0.0377,  0.1267,  0.0759,\n          0.0545, -0.0045,  0.0094,  0.0301]])\ntensor([[ 0.0334,  0.0743, -0.0769, -0.0052, -0.0897, -0.0131, -0.0057,  0.0266,\n          0.0655, -0.0867, -0.0552,  0.0814]])\ntensor([[ 0.0535,  0.0562, -0.0431, -0.0212, -0.0456, -0.0397,  0.0120,  0.0140,\n          0.0846, -0.1275, -0.0680,  0.0036]])\ntensor([[ 0.0731,  0.0501,  0.0714,  0.0169, -0.0092, -0.0566,  0.0675,  0.0191,\n          0.0266, -0.1432, -0.0657, -0.0834]])\ntensor([[ 0.1057,  0.0483,  0.1833,  0.1370,  0.0157, -0.0547,  0.1195,  0.0314,\n          0.0451, -0.1579, -0.0628, -0.1847]])\ntensor([[ 0.1037,  0.0425,  0.1173,  0.0733,  0.0634, -0.0989,  0.1119,  0.0721,\n          0.0407, -0.1588, -0.0788, -0.0311]])\ntensor([[ 0.0158,  0.0402, -0.0009,  0.0248,  0.1053, -0.1297,  0.0902,  0.0926,\n          0.0553, -0.1634, -0.1040,  0.0824]])\ntensor([[ 0.0056,  0.0442, -0.0927,  0.0439,  0.0970, -0.1381,  0.0525,  0.1032,\n          0.0726, -0.1593, -0.1176,  0.1721]])\ntensor([[ 0.0381,  0.0598, -0.0849,  0.0686,  0.0652, -0.1133,  0.0331,  0.0975,\n          0.0365, -0.1365, -0.1155,  0.1498]])\ntensor([[ 0.0624,  0.0725, -0.0782,  0.0804,  0.0299, -0.0924,  0.0254,  0.0835,\n          0.0208, -0.1092, -0.1088,  0.0977]])\ntensor([[ 0.0775,  0.0776, -0.0314,  0.0754,  0.0081, -0.0736,  0.0400,  0.0728,\n          0.0255, -0.0829, -0.0982,  0.0506]])\ntensor([[ 0.0810,  0.0723,  0.0378,  0.0591,  0.0066, -0.0646,  0.0613,  0.0636,\n          0.0461, -0.0655, -0.0868,  0.0214]])\ntensor([[ 0.0711,  0.0601,  0.1007,  0.0439,  0.0192, -0.0589,  0.0858,  0.0621,\n          0.0657, -0.0569, -0.0766,  0.0054]])\ntensor([[ 0.0601, -0.0002,  0.1459,  0.0371,  0.0267, -0.0512,  0.1022,  0.0621,\n          0.0796, -0.0478, -0.0657,  0.0038]])\ntensor([[ 0.0265,  0.0579,  0.1210,  0.0474, -0.0008, -0.0244,  0.0891,  0.0479,\n          0.0737,  0.0309, -0.0374,  0.0145]])\ntensor([[ 0.0189,  0.0515,  0.0572,  0.0504, -0.0221, -0.0129,  0.0747,  0.0400,\n          0.0580,  0.0677, -0.0250,  0.0269]])\ntensor([[ 0.0041,  0.0476,  0.0192,  0.0475, -0.0337, -0.0069,  0.0770,  0.0308,\n          0.0406,  0.0743, -0.0271,  0.0260]])\ntensor([[ 0.0282,  0.0652,  0.0127,  0.0572, -0.0182, -0.0102,  0.0554,  0.0368,\n          0.0273,  0.0909, -0.0235,  0.0419]])\ntensor([[ 0.0266,  0.0637,  0.0139,  0.0667, -0.0145,  0.0016,  0.0481,  0.0510,\n          0.0064,  0.0911, -0.0307,  0.0653]])\ntensor([[ 0.0335,  0.0698,  0.0177,  0.0732, -0.0094,  0.0026,  0.0485,  0.0555,\n          0.0086,  0.0877, -0.0308,  0.0724]])\ntensor([[ 0.0531,  0.0825,  0.0358,  0.0806,  0.0003,  0.0020,  0.0514,  0.0620,\n          0.0108,  0.0844, -0.0323,  0.0814]])\ntensor([[ 0.1140,  0.1095,  0.0965,  0.1089,  0.0238, -0.0024,  0.0635,  0.0771,\n          0.0469,  0.0831, -0.0398,  0.1048]])\ntensor([[ 0.1104,  0.0990,  0.0890,  0.1043,  0.0226, -0.0035,  0.0643,  0.0708,\n          0.0644,  0.0898, -0.0334,  0.0981]])\ntensor([[ 0.0991,  0.0822,  0.0846,  0.1006,  0.0280, -0.0044,  0.0666,  0.0706,\n          0.0777,  0.0887, -0.0316,  0.0920]])\ntensor([[ 0.0913,  0.0636,  0.0820,  0.0991,  0.0384, -0.0028,  0.0702,  0.0725,\n          0.0892,  0.0831, -0.0313,  0.0867]])\ntensor([[ 0.0807,  0.0446,  0.0777,  0.0930,  0.0499, -0.0019,  0.0734,  0.0755,\n          0.0936,  0.0774, -0.0299,  0.0800]])\ntensor([[ 0.0709,  0.0278,  0.0748,  0.0863,  0.0613, -0.0015,  0.0768,  0.0792,\n          0.0978,  0.0791, -0.0279,  0.0747]])\ntensor([[ 0.0645, -0.0018,  0.0751,  0.0787,  0.0771, -0.0030,  0.0845,  0.0860,\n          0.1098,  0.0861, -0.0282,  0.0724]])\ntensor([[ 0.0765, -0.0115,  0.0776,  0.0798,  0.0838, -0.0041,  0.0881,  0.0892,\n          0.1181,  0.0914, -0.0278,  0.0756]])\ntensor([[ 0.0913,  0.0126,  0.0792,  0.0817,  0.0857, -0.0064,  0.0888,  0.0904,\n          0.1194,  0.0875, -0.0259,  0.0793]])\ntensor([[ 0.1008,  0.0332,  0.0775,  0.0805,  0.0848, -0.0091,  0.0862,  0.0906,\n          0.1123,  0.0794, -0.0233,  0.0813]])\ntensor([[ 0.1001,  0.0470,  0.0694,  0.0736,  0.0789, -0.0120,  0.0818,  0.0889,\n          0.0890,  0.0693, -0.0188,  0.0804]])\ntensor([[ 0.0967,  0.0591,  0.0646,  0.0683,  0.0743, -0.0145,  0.0781,  0.0876,\n          0.0680,  0.0698, -0.0154,  0.0784]])\ntensor([[ 0.1013,  0.0791,  0.0643,  0.0711,  0.0725, -0.0160,  0.0747,  0.0865,\n          0.0613,  0.0787, -0.0131,  0.0789]])\ntensor([[ 0.1054,  0.0979,  0.0673,  0.0741,  0.0756, -0.0186,  0.0730,  0.0881,\n          0.0563,  0.0900, -0.0118,  0.0800]])\ntensor([[ 0.0989,  0.1120,  0.0703,  0.0755,  0.0778, -0.0202,  0.0718,  0.0893,\n          0.0501,  0.0967, -0.0108,  0.0803]])\ntensor([[ 0.0922,  0.1257,  0.0748,  0.0792,  0.0826, -0.0218,  0.0721,  0.0913,\n          0.0487,  0.1012, -0.0106,  0.0810]])\ntensor([[ 0.0877,  0.1410,  0.0803,  0.0852,  0.0876, -0.0229,  0.0732,  0.0935,\n          0.0598,  0.1059, -0.0110,  0.0829]])\ntensor([[ 0.0724,  0.1336,  0.0789,  0.0861,  0.0858, -0.0219,  0.0748,  0.0930,\n          0.0675,  0.0934, -0.0113,  0.0820]])\ntensor([[ 0.0621,  0.1270,  0.0784,  0.0912,  0.0851, -0.0209,  0.0786,  0.0934,\n          0.0896,  0.0721, -0.0121,  0.0815]])\ntensor([[ 0.0677,  0.1098,  0.0755,  0.0926,  0.0851, -0.0204,  0.0806,  0.0928,\n          0.0973,  0.0694, -0.0132,  0.0807]])\ntensor([[ 0.0810,  0.0937,  0.0739,  0.0945,  0.0870, -0.0215,  0.0830,  0.0939,\n          0.1029,  0.0762, -0.0140,  0.0817]])\ntensor([[ 0.0918,  0.0543,  0.0599,  0.0899,  0.0684, -0.0221,  0.0818,  0.0882,\n          0.0805,  0.0964, -0.0112,  0.0758]])\ntensor([[ 0.0958,  0.0664,  0.0637,  0.0909,  0.0685, -0.0235,  0.0818,  0.0898,\n          0.0792,  0.1047, -0.0095,  0.0769]])\ntensor([[ 0.0987,  0.0810,  0.0688,  0.0921,  0.0704, -0.0249,  0.0818,  0.0921,\n          0.0784,  0.1136, -0.0089,  0.0783]])\ntensor([[ 0.0916,  0.0910,  0.0697,  0.0890,  0.0673, -0.0251,  0.0815,  0.0914,\n          0.0743,  0.1120, -0.0082,  0.0778]])\ntensor([[ 0.0787,  0.0959,  0.0683,  0.0837,  0.0616, -0.0241,  0.0809,  0.0882,\n          0.0688,  0.0987, -0.0084,  0.0774]])\ntensor([[ 0.0725,  0.0977,  0.0704,  0.0813,  0.0611, -0.0239,  0.0816,  0.0878,\n          0.0684,  0.0846, -0.0090,  0.0779]])\ntensor([[ 0.0824,  0.0998,  0.0780,  0.0854,  0.0704, -0.0251,  0.0841,  0.0922,\n          0.0737,  0.0776, -0.0092,  0.0798]])\ntensor([[ 0.0856,  0.0929,  0.0828,  0.0874,  0.0766, -0.0253,  0.0859,  0.0948,\n          0.0763,  0.0675, -0.0105,  0.0823]])\ntensor([[ 0.0926,  0.0866,  0.0906,  0.0927,  0.0869, -0.0265,  0.0882,  0.0999,\n          0.0817,  0.0684, -0.0116,  0.0862]])\ntensor([[ 0.0936,  0.0716,  0.0953,  0.0956,  0.0962, -0.0285,  0.0887,  0.1043,\n          0.0861,  0.0763, -0.0129,  0.0899]])\ntensor([[ 0.0879,  0.0752,  0.0936,  0.0945,  0.0940, -0.0285,  0.0875,  0.1032,\n          0.0862,  0.0795, -0.0125,  0.0895]])\ntensor([[ 0.0838,  0.0821,  0.0925,  0.0926,  0.0928, -0.0293,  0.0862,  0.1029,\n          0.0868,  0.0882, -0.0120,  0.0894]])\ntensor([[ 0.0774,  0.0871,  0.0863,  0.0887,  0.0861, -0.0293,  0.0837,  0.0983,\n          0.0850,  0.0930, -0.0113,  0.0876]])\ntensor([[ 0.0718,  0.0886,  0.0790,  0.0844,  0.0785, -0.0290,  0.0813,  0.0932,\n          0.0828,  0.0930, -0.0109,  0.0855]])\ntensor([[ 0.0713,  0.0897,  0.0723,  0.0812,  0.0714, -0.0287,  0.0791,  0.0882,\n          0.0809,  0.0883, -0.0107,  0.0833]])\ntensor([[ 0.0727,  0.0906,  0.0675,  0.0794,  0.0662, -0.0284,  0.0777,  0.0845,\n          0.0808,  0.0847, -0.0104,  0.0818]])\ntensor([[ 0.0748,  0.0896,  0.0632,  0.0782,  0.0624, -0.0274,  0.0770,  0.0820,\n          0.0803,  0.0806, -0.0098,  0.0808]])\ntensor([[ 0.0778,  0.0871,  0.0617,  0.0779,  0.0604, -0.0270,  0.0774,  0.0808,\n          0.0821,  0.0776, -0.0092,  0.0805]])\ntensor([[ 0.0823,  0.0843,  0.0620,  0.0779,  0.0613, -0.0277,  0.0785,  0.0803,\n          0.0848,  0.0764, -0.0094,  0.0811]])\ntensor([[ 0.0900,  0.0829,  0.0684,  0.0802,  0.0669, -0.0295,  0.0807,  0.0817,\n          0.0909,  0.0790, -0.0103,  0.0833]])\ntensor([[ 0.0942,  0.0799,  0.0724,  0.0818,  0.0701, -0.0302,  0.0823,  0.0824,\n          0.0939,  0.0796, -0.0105,  0.0845]])\ntensor([[ 0.0899,  0.0701,  0.0721,  0.0799,  0.0682, -0.0296,  0.0832,  0.0789,\n          0.0904,  0.0749, -0.0110,  0.0839]])\ntensor([[ 0.0809,  0.0707,  0.0738,  0.0792,  0.0680, -0.0294,  0.0832,  0.0771,\n          0.0878,  0.0738, -0.0118,  0.0840]])\ntensor([[ 0.0773,  0.0751,  0.0757,  0.0795,  0.0693, -0.0294,  0.0834,  0.0774,\n          0.0856,  0.0755, -0.0119,  0.0844]])\ntensor([[ 0.0733,  0.0784,  0.0763,  0.0793,  0.0694, -0.0287,  0.0826,  0.0775,\n          0.0811,  0.0764, -0.0118,  0.0846]])\ntensor([[ 0.0696,  0.0815,  0.0767,  0.0789,  0.0696, -0.0282,  0.0816,  0.0778,\n          0.0768,  0.0777, -0.0117,  0.0848]])\ntensor([[ 0.0696,  0.0839,  0.0765,  0.0790,  0.0693, -0.0284,  0.0815,  0.0789,\n          0.0737,  0.0790,  0.0184,  0.0848]])\ntensor([[ 0.0683,  0.0852,  0.0745,  0.0787,  0.0676, -0.0271,  0.0804,  0.0790,\n          0.0699,  0.0796,  0.0558,  0.0838]])\ntensor([[ 0.0694,  0.0866,  0.0723,  0.0785,  0.0661, -0.0264,  0.0792,  0.0782,\n          0.0690,  0.0812,  0.0879,  0.0824]])\ntensor([[ 0.0670,  0.0849,  0.0670,  0.0766,  0.0598, -0.0231,  0.0771,  0.0758,\n          0.0660,  0.0782,  0.1073,  0.0791]])\ntensor([[ 0.0655,  0.0729,  0.0598,  0.0717,  0.0488, -0.0213,  0.0730,  0.0729,\n          0.0673,  0.0686,  0.1323,  0.0767]])\ntensor([[ 0.0709,  0.0746,  0.0631,  0.0747,  0.0545, -0.0227,  0.0759,  0.0728,\n          0.0742,  0.0753,  0.1599,  0.0753]])\ntensor([[ 0.0760,  0.0761,  0.0674,  0.0760,  0.0602, -0.0246,  0.0777,  0.0736,\n          0.0790,  0.0783,  0.1855,  0.0750]])\ntensor([[ 0.0776,  0.0765,  0.0700,  0.0776,  0.0629, -0.0256,  0.0793,  0.0748,\n          0.0821,  0.0779,  0.2087,  0.0751]])\ntensor([[ 0.1831,  0.1952,  0.1739,  0.1428,  0.1453, -0.0359,  0.0977,  0.1206,\n          0.1226,  0.1776,  0.4012,  0.0888]])\ntensor([[ 0.2061,  0.2101,  0.1892,  0.1615,  0.1562, -0.0307,  0.0954,  0.1183,\n          0.1345,  0.1552,  0.3462,  0.0915]])\nie episode : 1\nTrack generation: 1224..1538 -> 314-tiles track\ntensor([[ 0.1360,  0.2003,  0.1690,  0.1408,  0.1331, -0.0739,  0.1098,  0.1338,\n          0.1221,  0.0765, -0.0166,  0.0781]])\ntensor([[ 0.1101,  0.1450,  0.1444,  0.1378,  0.1168, -0.0495,  0.1002,  0.1081,\n          0.1023,  0.0877, -0.0950,  0.0667]])\ntensor([[ 0.0855,  0.1127,  0.1440,  0.1515,  0.1041, -0.0235,  0.1165,  0.0989,\n          0.1334,  0.1143, -0.1046,  0.0639]])\ntensor([[0.0408, 0.1290, 0.1334, 0.1496, 0.0767, 0.0979, 0.1327, 0.0980, 0.1804,\n         0.1451, 0.0677, 0.0690]])\ntensor([[0.0195, 0.1525, 0.1244, 0.1431, 0.0601, 0.1293, 0.1267, 0.0951, 0.1562,\n         0.1520, 0.1414, 0.0719]])\ntensor([[0.0432, 0.1647, 0.1116, 0.1355, 0.0488, 0.1467, 0.1247, 0.1018, 0.1310,\n         0.1499, 0.1810, 0.0766]])\ntensor([[0.0829, 0.1690, 0.1098, 0.1334, 0.0527, 0.1707, 0.1313, 0.1168, 0.1187,\n         0.1528, 0.1976, 0.0890]])\ntensor([[0.1166, 0.1559, 0.1049, 0.1278, 0.0586, 0.1844, 0.1373, 0.1322, 0.1153,\n         0.1478, 0.2054, 0.1001]])\ntensor([[0.1473, 0.1438, 0.1055, 0.1255, 0.0713, 0.2022, 0.1468, 0.1553, 0.1136,\n         0.1476, 0.2175, 0.1139]])\ntensor([[0.1723, 0.1341, 0.1024, 0.1218, 0.0722, 0.2132, 0.1502, 0.1681, 0.1201,\n         0.1509, 0.2041, 0.1220]])\ntensor([[0.1966, 0.1361, 0.1031, 0.1214, 0.0768, 0.2290, 0.1561, 0.1839, 0.1431,\n         0.1601, 0.1979, 0.1330]])\ntensor([[0.2158, 0.1490, 0.1052, 0.1219, 0.0806, 0.2469, 0.1608, 0.1936, 0.1667,\n         0.1718, 0.1928, 0.1450]])\ntensor([[0.2296, 0.1578, 0.1083, 0.1203, 0.0804, 0.2572, 0.1620, 0.1953, 0.1856,\n         0.1772, 0.1760, 0.1547]])\ntensor([[0.2435, 0.1679, 0.1157, 0.1246, 0.0836, 0.2693, 0.1645, 0.1970, 0.2034,\n         0.1821, 0.1615, 0.1647]])\ntensor([[0.2280, 0.1643, 0.1147, 0.1225, 0.0778, 0.2625, 0.1586, 0.1878, 0.2081,\n         0.1725, 0.1378, 0.1663]])\ntensor([[0.1864, 0.1398, 0.1044, 0.1121, 0.0542, 0.1982, 0.1367, 0.1572, 0.1791,\n         0.1412, 0.1000, 0.1537]])\ntensor([[0.1646, 0.1180, 0.1045, 0.1043, 0.0368, 0.1486, 0.1189, 0.1370, 0.1685,\n         0.1148, 0.0781, 0.1412]])\ntensor([[0.1596, 0.1218, 0.1093, 0.1099, 0.0396, 0.1329, 0.1173, 0.1392, 0.1690,\n         0.1142, 0.0873, 0.1435]])\ntensor([[0.1628, 0.1347, 0.1250, 0.1229, 0.0519, 0.1286, 0.1224, 0.1528, 0.1764,\n         0.1238, 0.1146, 0.1532]])\ntensor([[0.1442, 0.1623, 0.1460, 0.1497, 0.0669, 0.1434, 0.1350, 0.1718, 0.1644,\n         0.1423, 0.1491, 0.1697]])\ntensor([[0.1295, 0.1616, 0.1468, 0.1552, 0.0661, 0.1422, 0.1350, 0.1700, 0.1439,\n         0.1429, 0.1548, 0.1710]])\ntensor([[0.1184, 0.1515, 0.1467, 0.1563, 0.0624, 0.1354, 0.1308, 0.1635, 0.1242,\n         0.1378, 0.1589, 0.1679]])\ntensor([[0.1111, 0.1347, 0.1437, 0.1544, 0.0554, 0.1250, 0.1224, 0.1520, 0.1075,\n         0.1275, 0.1615, 0.1569]])\ntensor([[0.1059, 0.1209, 0.1414, 0.1514, 0.0506, 0.1190, 0.1163, 0.1431, 0.1023,\n         0.1220, 0.1636, 0.1478]])\ntensor([[0.1034, 0.1207, 0.1402, 0.1520, 0.0502, 0.1236, 0.1169, 0.1407, 0.0994,\n         0.1287, 0.1658, 0.1454]])\ntensor([[0.0932, 0.1442, 0.1387, 0.1590, 0.0594, 0.1390, 0.1301, 0.1499, 0.1006,\n         0.1492, 0.1665, 0.1585]])\n"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-a6e9d7f69b96>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi_step\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_horizon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_from_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-29e2eb9bdf5e>\u001b[0m in \u001b[0;36mlearn_from_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mtab_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/share/virtualenvs/code-i1XZ64Tp/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/share/virtualenvs/code-i1XZ64Tp/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["run()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":"[<matplotlib.lines.Line2D at 0x1457b57b8>]"},"execution_count":21,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 368.925 248.518125\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 368.925 248.518125 \nL 368.925 0 \nL -0 0 \nz\n\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 361.725 224.64 \nL 361.725 7.2 \nL 26.925 7.2 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m952f54e503\" style=\"stroke:#ffffff;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"42.143182\" xlink:href=\"#m952f54e503\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(38.961932 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"90.074463\" xlink:href=\"#m952f54e503\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(83.711963 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"138.005744\" xlink:href=\"#m952f54e503\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(131.643244 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"185.937026\" xlink:href=\"#m952f54e503\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(179.574526 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"233.868307\" xlink:href=\"#m952f54e503\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(227.505807 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"281.799588\" xlink:href=\"#m952f54e503\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(272.255838 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"329.73087\" xlink:href=\"#m952f54e503\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(320.18712 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m7684496141\" style=\"stroke:#ffffff;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7684496141\" y=\"214.756414\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(13.5625 218.555633)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7684496141\" y=\"184.623826\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(13.5625 188.423045)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7684496141\" y=\"154.491238\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 4 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(13.5625 158.290457)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7684496141\" y=\"124.358651\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 6 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(13.5625 128.157869)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7684496141\" y=\"94.226063\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 8 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(13.5625 98.025281)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7684496141\" y=\"64.093475\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 10 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 67.892694)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7684496141\" y=\"33.960887\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 12 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 37.760106)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p1ee03a49c1)\" d=\"M 42.143182 214.755433 \nL 44.539746 17.083636 \nL 46.93631 207.861257 \nL 49.332874 213.441774 \nL 51.729438 213.998687 \nL 56.522566 214.687388 \nL 68.505387 214.696779 \nL 70.901951 214.741743 \nL 73.298515 214.512002 \nL 75.695079 214.736025 \nL 78.091643 214.734483 \nL 80.488207 214.616303 \nL 82.884771 214.719953 \nL 90.074463 214.74191 \nL 284.196152 214.701362 \nL 286.592717 214.56871 \nL 288.989281 214.715351 \nL 298.575537 214.733447 \nL 346.506818 214.745275 \nL 346.506818 214.745275 \n\" style=\"fill:none;stroke:#8dd3c7;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 361.725 224.64 \nL 361.725 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 361.725 224.64 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 361.725 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1ee03a49c1\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{},"output_type":"display_data"}],"source":["plt.plot(tab_loss)\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}