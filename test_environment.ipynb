{"cells":[{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["import numpy\n","import numpy as np\n","import itertools as it \n","import gym\n","import torch\n","import torch.nn.functional as F \n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n",""]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["#copy\n","\n","class ScaleFloatFram(gym.ObservationWrapper):\n","    def observation(self, obs):\n","        return np.array(obs).astype(np.float64)\n","\n","def make_env(env_name):\n","    env = gym.make(env_name)\n","    return ScaleFloatFram(env)\n",""]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"env_name = \"CarRacing-v0\"\nenv = make_env(env_name)\nob =env.reset()"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"#To understand\ndef one_step(i :int):\n    action = env.action_space.sample()\n    #action = [0,1,1]\n    observation, reward, done, info = env.step(action)\n    if (i%10==0):\n        print(f\" action : {action}\")\n        print(f\"reward : {reward}\")\n        print(f\"done : {done}\")\n        plt.show()\n        plt.imshow(observation)\n        print(\"------------------\")\n\n"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"for i in range(50):\n    one_step(i)"},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":"\n    # Random seed\nnp.random.RandomState(42)\n\nn_episode = 4\nmax_horizon = 1000\n#eval_steps = 10\nbatch_size = 10\ngamma = 0.9 \n#batch_size = 2\n#direction frein acceleration\nall_actions = np.array( [k for k in it.product([-1, 0, 1], [1, 0], [0.2, 0])])\nnb_actions = len(all_actions)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"class Unflatten(nn.Module):\n    \"\"\"\n    An Unflatten module receives an input of shape (N, C*H*W) and reshapes it\n    to produce an output of shape (N, C, H, W).\n    \"\"\"\n    def __init__(self, N=-1, C=3,H=96, W=96):\n        super(Unflatten, self).__init__()\n        self.N = N\n        self.C = C\n        self.H = H\n        self.W = W\n    def forward(self, x):\n        return x.view(self.N, self.C,self.H, self.W)\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        N, C, H, W = x.size() # read in N, C, H, W\n        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["def Q_model(input_dim=96*96*3, output_dim=nb_actions, trainable=True ):\n","    \"\"\"\n","    Build and return a PyTorch model implementing the architecture above.\n","    \"\"\"\n","    model = nn.Sequential(\n","            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","            Unflatten(batch_size, 3, 96, 96),\n","            #Unflatten(1, 3, 96, 96),\n","            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=7, stride=3), #46\n","            nn.LeakyReLU(inplace=True, negative_slope=0.01),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2), #42\n","            nn.LeakyReLU(inplace=True, negative_slope=0.01),\n","            nn.MaxPool2d(kernel_size=2, stride=2), #21\n","            Flatten(),\n","            nn.Linear(288, 256),\n","            nn.LeakyReLU(inplace=True, negative_slope=0.01),\n","            nn.Linear(256, nb_actions),\n","\n","            #nn.Linear(input_dim,48),\n","            #nn.LeakyReLU(0.01),\n","            #nn.Linear(48,48),\n","            #nn.LeakyReLU(0.01),\n","            #nn.Linear(48,output_dim)\n","            \n","\n","            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    )\n","    return model"]},{"cell_type":"markdown","execution_count":47,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"can't assign to function call (<ipython-input-47-f302ac683773>, line 1)","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-f302ac683773>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    torch.Size([2, 28224]) = 64 * 21 *21\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"]}],"source":"torch.Size([2, 28224]) = 64 * 21 *21\n"},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"torch.Size([2, 96, 96, 3])\ntensor([-0.1008,  2.8430,  3.5826,  3.0177, -3.0547, -1.6477,  3.4126, -1.4135,\n         4.4919, -0.2697, -2.5728, -2.1247], grad_fn=<SelectBackward>)\n"},{"data":{"text/plain":"8"},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":"#print(X.shape)\n\n\n\nD = list()\ns=ob\nall_actions = np.array( [k for k in it.product([-1, 0, 1], [1, 0], [0.2, 0])])\naction = all_actions[0]\nreward =1\nobservation = ob\n\nD.append({\"st\":s,\"at\":action,\"rt\":reward,\"st+1\":observation})\nD.append({\"st\":s,\"at\":action,\"rt\":reward,\"st+1\":observation})\ntransitions = np.random.choice(D, size=2, replace=False)\nX = np.array([ (transi[\"st\"]) for transi in transitions])\nX = torch.from_numpy(X).float()\ny = np.array([ transi[\"rt\"]for transi in transitions])\n\nnum_frame_stack = 4\npic_size=(96, 96)\n\ndim_input_batch = (batch_size, num_frame_stack) + pic_size\ndim_input_batch\n\n\nstate_a = np.array([ob], copy = False)\nstate_v = torch.tensor(state_a)\nq_val = Q_model(state_v)\nprint(q_val)\n_, act_v = torch.max(q_val, dim=1)\naction = int(act_v.item())\n\n\n\nreal_data = Variable(X)\nprint(real_data.shape)\nQ = Q_model()\nanswer = Q(real_data)\nprint(answer[0])\nnp.argmax(answer[0].detach().numpy())"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["Q = Q_model()\n","memory = list()\n","\n","def main():\n","    for i_episode in range(n_episode):\n","        observation = env.reset()\n","        observation =torch.from_numpy(observation).float()\n","        for i_step in range(max_horizon):\n","            print(observation.shape)\n","            print(Q(observation))\n","            #Q_current = Q(Variable(observation)))\n","            greedy_ind = np.argmax(Q(observation).detach().numpy())\n","            action = all_actions[greedy_ind]\n","\n","            #action = env.action_space.sample()\n","            \n","            observation, reward, done, info = env.step(action)\n","            memory.append({\"st\":observation,\"at\":action,\"rt\":reward,\"st+1\":observation})\n","            selection = numpy.random.choice(memory, size=batch_size, replace=True)\n","            #print((selection))\n","            X = np.array([ transi[\"st\"]for transi in selection])\n","            X = torch.from_numpy(X).float()\n","            y=torch.empty(batch_size)\n","            for m in range(batch_size):\n","                y[m] = selection[m][\"rt\"]\n","                if (done == False):\n","                    y[m] += gamma*Q(observation)\n","            Q_value = Q(X)\n","            print(Q_value)\n","            loss = F.mse_loss(Q_value, y)\n","            print(loss)\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","       \n","\n","    \n","\n",""]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["main()"]},{"cell_type":"code","execution_count":143,"metadata":{},"outputs":[],"source":"(96, 96, 3)\n\nclass Unflatten(nn.Module):\n    \"\"\"\n    An Unflatten module receives an input of shape (N, C*H*W) and reshapes it\n    to produce an output of shape (N, C, H, W).\n    \"\"\"\n    def __init__(self, N=-1, C=3,H=96, W=96):\n        super(Unflatten, self).__init__()\n        self.N = N\n        self.C = C\n        self.H = H\n        self.W = W\n    def forward(self, x):\n        return x.view(self.N, self.C,self.H, self.W)"},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":"class Flatten(nn.Module):\n    def forward(self, x):\n        N, C, H, W = x.size() # read in N, C, H, W\n        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'time' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-3df6a8f24c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# bring data to the computing device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"]}],"source":"\n        start = time()\n        for batch_idx, (data, target) in enumerate(trainset_loader):\n            # bring data to the computing device, e.g. GPU\n            data, target = data.to(device), target.to(device)\n\n            # forward pass\n            output = model(data)\n            # compute loss: negative log-likelihood\n            loss = F.nll_loss(output, target)\n            \n            # backward pass\n            # clear the gradients of all tensors being optimized.\n            optimizer.zero_grad()\n            # accumulate (i.e. add) the gradients from this forward pass\n            loss.backward()\n            # performs a single optimization step (parameter update)\n            optimizer.step()\n            \n            if iteration % log_interval == 0:\n                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n                    100. * batch_idx / len(trainset_loader), loss.item()))\n            iteration += 1\n            \n        end = time()"},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"UsageError: Line magic function `%pycache` not found.\n"}],"source":["%pycache\n","def build_dc_classifier():\n","    \"\"\"\n","    Build and return a PyTorch model for the DCGAN discriminator implementing\n","    the architecture above.\n","    \"\"\"\n","    return nn.Sequential(\n","        Unflatten(BATCH_SIZE, 1, 28, 28),\n","        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1),\n","        nn.LeakyReLU(inplace=True, negative_slope=0.01),\n","        nn.MaxPool2d(kernel_size=2, stride=2),\n","        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1),\n","        nn.LeakyReLU(inplace=True, negative_slope=0.01),\n","        nn.MaxPool2d(kernel_size=2, stride=2),\n","        Flatten(),\n","        nn.Linear(4*4*64, 4*4*64),\n","        nn.LeakyReLU(inplace=True, negative_slope=0.01),\n","        nn.Linear(4*4*64, 1),\n","    )\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}